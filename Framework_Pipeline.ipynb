{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('./src') \n",
    "from xgboost_utils import train_xgb\n",
    "from xgboost_predictor import generate_sparse_pgv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Train XGBoost Models and Generate Sparse Maps\n",
    "\n",
    "1- We train one XGBoost model per receiver  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load input and output data for receiver\n",
    "receiver_idx         = 139   # choose a receiver index from 0 to 255\n",
    "receiver_database    = np.load(f'/media/wolf6819/Elements/reciprocal_db/receiver_{receiver_idx}_database.npz')\n",
    "inputs  = receiver_database['inputs']   # source coords and mechanism ([distance, azimuth, depth, strike, dip, rake, radiation, takeoff] )\n",
    "outputs = receiver_database['outputs']  # pgv along two components (East-West, North-South) in mm/s\n",
    "\n",
    "# train xgboost model \n",
    "pgv_true, pgv_pred = train_xgb(inputs, np.log(outputs[:,0]))  \n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.scatter(pgv_true, pgv_pred)\n",
    "ax.plot([-2, 7], [-2, 7], 'k--')\n",
    "ax.set_xlabel('True log(PGV) (mm/s)')\n",
    "ax.set_ylabel('Predicted log(PGV) (mm/s)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- We repeat the process above for all the receivers. The trained models for each receiver \n",
    "and for each of the components (East and North) are stored in the `models/` directory. \n",
    "\n",
    "3 - We use the trained XGBoost models to generate sparse PGV maps for the forward simulations (used as input for Step 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sparse PGV map for input source coordinates and focal mechanism\n",
    "# we show an example of generating sparse maps for a database with 50 source locations, and 50 mechanims per location refered to as 50_50\n",
    "\n",
    "data_tag   = '50_50'  \n",
    "models_dir = '/media/wolf6819/Elements/models/'\n",
    "spacing_km = 4 \n",
    "station_coords_path = 'data/station_coords_sparse.npz' \n",
    "output_path         = 'data/step1_preds'\n",
    "\n",
    "sparse_maps = generate_sparse_pgv(station_coords_path, models_dir, output_path, data_tag, spacing_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an example of a sparse PGV map  \n",
    "station_coords_file = 'data/station_coords_sparse.npz'  \n",
    "station_coords       = np.load(station_coords_file)['station_coords']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.scatter(station_coords[:,0]/1e3, station_coords[:,1]/1e3, c = sparse_maps[100,:,:,0], s=100, cmap='plasma')\n",
    "ax.set_xlabel('East Distance (km)') \n",
    "ax.set_ylabel('North Distance (km)')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Train the Encoder-MLP on Sparse Maps\n",
    "\n",
    "We use the predicted sparse maps to train an EncoderMLP network \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "from encoderMLP_predictor import run_train  \n",
    "\n",
    "# Manual config \n",
    "config = SimpleNamespace(\n",
    "  \n",
    "    mode              = \"train\",\n",
    "    data_tag          = \"50_50_x4\",\n",
    "    downsample_factor = 4,\n",
    "    \n",
    "    # additional defaults \n",
    "    data_dir=\"data/\",\n",
    "    transform_input=True,\n",
    "    transform_output=True,\n",
    "    inc_gradient=False,\n",
    "    inc_distance=True,\n",
    "    normalize_output=True,\n",
    "    normalize_input=True,\n",
    "    nx_patch=8,\n",
    "    ny_patch=8,\n",
    "    fourier_features=False,\n",
    "    D=32,\n",
    "    gamma=5.0,\n",
    "    n_samp_pts_per_patch=512,\n",
    "    split=0.8,\n",
    "    batch_size=32,\n",
    "    learning_rate=1e-3,\n",
    "    loss_type=\"mse\",\n",
    "    optimizer=\"adamw\",\n",
    "    num_epochs=1, \n",
    "    enc_type=\"edsr\",\n",
    "    in_channels=5,\n",
    "    out_channels=32,\n",
    "    conv_kernel_size=3,\n",
    "    attention_kernel_size=1,\n",
    "    num_features=32,\n",
    "    num_blocks=8,\n",
    "    nf=32,\n",
    "    activation=\"sine\",\n",
    "    pad_size=4,\n",
    "    sigma=3.0,\n",
    "    results_dir=None,\n",
    "    stats_tag=None\n",
    ")\n",
    "\n",
    "# Run training\n",
    "run_train(config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we test the trained network on an independent set of test events, the results are stored in the relevant dir in the `./results` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from encoderMLP_predictor import run_test\n",
    "from types import SimpleNamespace\n",
    "\n",
    "with open(\"results/20250620_100749_23ec4b/config.yaml\", \"r\") as f:\n",
    "    cfg_dict = yaml.safe_load(f)\n",
    "\n",
    "config             = SimpleNamespace(**cfg_dict)\n",
    "config.mode        = \"test\"\n",
    "config.results_dir = \"results/20250620_100749_23ec4b\"\n",
    "\n",
    "# Run testing\n",
    "run_test(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We show an example of the true (simulated) vs predicted PGV maps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.load('results/results_70_50/test_preds.npy')\n",
    "gts   = np.load('results/results_70_50/test_gts.npy')  \n",
    "\n",
    "\n",
    "# choose a random idx between 0 and the number of samples in preds  \n",
    "idx  = np.random.randint(0, preds.shape[0])\n",
    "idx  = 266\n",
    "comp = 1  # choose component 0 (East-West) or 1 (North-South)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))  \n",
    "pred = preds[idx,:,:,comp]/10  # predicted PGV    \n",
    "gt   = gts[idx,:,:,comp]/10    # true PGV\n",
    "norm = plt.Normalize(vmin=0, vmax=np.max(gt)) \n",
    "\n",
    "cf0 = ax[0].contourf(gt, cmap='plasma', norm=norm)\n",
    "cf1 = ax[1].contourf(pred, cmap='plasma', norm=norm)\n",
    "\n",
    "ax[0].set_title('True PGV')    \n",
    "ax[1].set_title('Predicted PGV')\n",
    "ax[0].set_xlabel('East Distance (km)')  \n",
    "ax[0].set_ylabel('North Distance (km)') \n",
    "ax[1].set_xlabel('East Distance (km)')  \n",
    "\n",
    "fig.subplots_adjust(right=0.85)  \n",
    "cbar_ax = fig.add_axes([0.88, 0.15, 0.02, 0.7]) \n",
    "fig.colorbar(cf1, cax=cbar_ax, norm = norm).set_label(\"PGV (cm/s)\", fontsize=14)\n",
    "# add text to both subplots with max pgv in each \n",
    "ax[0].text(0.05, 0.1, f'Max PGV: {np.max(gt):.2f} cm/s', transform=ax[0].transAxes,fontsize=12,verticalalignment='top',\n",
    "           bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.3'))\n",
    "ax[1].text(0.05, 0.1, f'Max PGV: {np.max(pred):.2f} cm/s', transform=ax[1].transAxes, fontsize=12, verticalalignment='top',\n",
    "           bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.3'))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_params = np.load('data/forward_db/source_params_70_50.npz')['source_params']\n",
    "test_ids      = np.load('results/results_70_50/test_ids.npy')  \n",
    "\n",
    "error = np.abs(preds - gts)\n",
    "mean_error = np.mean(error, axis =(1, 2, 3))  # mean error across spatial dimensions\n",
    "print(mean_error.shape)\n",
    "params = source_params[test_ids]\n",
    "print(params.shape)\n",
    "# change the first two parameters to East and North distance in km\n",
    "params[:, 0] /= 1000  # East Distance in km\n",
    "params[:, 1] /= 1000  # North Distance in km\n",
    "param_names = [\"East Distance (km)\", \"North Distance (km)\", \"Depth (km)\", \"Strike (°)\", \"Dip (°)\", \"Rake (°)\"]  # replace with your actual names\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8), sharey=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    if i < params.shape[1]:\n",
    "        ax.scatter(params[:, i], mean_error/10, s=30, alpha=0.7, edgecolors='k', linewidth=0.5)\n",
    "        ax.set_xlabel(param_names[i])\n",
    "        if i % 3 == 0:\n",
    "            ax.set_ylabel(\"Mean Absolute Error (cm/s)\")\n",
    "            \n",
    "        ax.grid(True, linestyle='--', alpha=0.5)\n",
    "        ax.set_ylim(0, 0.35)  #\n",
    "        ax.set_yticks(np.arange(0, 0.35, 0.1))\n",
    "    else:\n",
    "        ax.axis('off')  \n",
    "        ax.locator_params(axis='x', nbins=5)  \n",
    "        ax.locator_params(axis='y', nbins=5) \n",
    "\n",
    "# set axis for the first two subplots \n",
    "axes[0, 0].set_xlim(-25, 25)  # East Distance (km)    \n",
    "axes[0, 1].set_xlim(-25, 25)  # North Distance (km)   \n",
    "fig.tight_layout(rect=[0, 0, 1, 0.95])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pgvtrial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
